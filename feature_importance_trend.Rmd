---
title: "Analysis"
author: "Bas van Remmerden"
date: "`r Sys.Date()`"
output: html_document
---


# Set up
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
options(scipen=999)
```

# Setting seed
```{r}
set.seed(123)
```

## Loading libraries
Loading the required libraries
```{r warning = F, message = F}
#### Installing/loading packages
required_packages <- c(
  "tidyverse",
  "lubridate",
  "tidymodels",
  "beepr",
  "stargazer",
  "extrafont",
  "gridExtra",
  "ranger",
  "vip",
  "pdp",
  "iml",
  "DALEX"
)

# install.packages(packages_to_install)
for (pkg in required_packages) {
  require(pkg, character.only = TRUE)
}

# Cleaning the environment before analysis
rm(pkg, required_packages)

# Loading more fonts
#font_import()
loadfonts(device = "win")
```
## Setting functions
```{r}
plot_single_partial_dependence_ggplot <- function(pdp_data) {
  pdp_df <- pdp_data$agr_profiles
  
  p <- ggplot(pdp_df, aes(x = `_x_`, y = `_yhat_`)) +
    geom_line() +
    geom_point() +
    labs(
      title = "",
      x = "Feature Value",
      y = "Predicted Value"
    ) +
    theme_classic() +
    theme(
    text = element_text(family = "Times New Roman", size = 16)) +
    facet_wrap(~ `_vname_`, scales = "free_x", ncol = 3)
  
  return(p)
}
```

# Loading the data
```{r}
load("data/analysis.RData")
load("data/analysis_smote.RData")
```

# Data preparation regular
```{r}
# Filter
df.analysis_filt <- df.analysis %>%
  filter(irregularity != 2) %>% # Filtering out all non-restatement observations
  mutate(irregularity = as.factor(irregularity))


# Splitting the data
split_testing <- initial_split(
  data = df.analysis_filt, prop = .8,
  strata = irregularity # Stratisfy on irregularity to 
                        # make sure there are enough fraud cases
)

df.analysis_test <- testing(split_testing)
df.analysis_train_assess <- training(split_testing)


# Splitting the data
split_assessment <- initial_split(
  data = df.analysis_train_assess, prop = .6,
  strata = irregularity # Stratisfy on irregularity to 
                        # make sure there are enough fraud cases
)



df.analysis_train <- training(split_assessment)
df.analysis_assess <- testing(split_assessment)





# Cross validation
cv_folds <- df.analysis_train %>% vfold_cv(v = 5, strata = irregularity) # Stratisfy on irregularity to 
                                                                         # make sure there are enough fraud cases

```

# Data preparation SMOTE
```{r}
df.analysis_smote_orig <- df.analysis_smote

# Filter
df.analysis_smote <- df.analysis_smote %>%
  mutate(irregularity = as.factor(irregularity_smote)) %>%
  select(-irregularity_smote)


# Splitting the data
split_testing_smote <- initial_split(
  data = df.analysis_smote, prop = .8,
  strata = irregularity # Stratisfy on irregularity to 
                        # make sure there are enough fraud cases
)

df.analysis_test_smote <- testing(split_testing_smote)
df.analysis_train_assess_smote <- training(split_testing_smote)


# Splitting the data
split_assessment_smote <- initial_split(
  data = df.analysis_train_assess_smote, prop = .6,
  strata = irregularity # Stratisfy on irregularity to 
                        # make sure there are enough fraud cases
)



df.analysis_train_smote <- training(split_assessment_smote)
df.analysis_assess_smote <- testing(split_assessment_smote)





# Cross validation
cv_folds_smote <- df.analysis_train_smote %>% vfold_cv(v = 5, strata = irregularity) # Stratisfy on irregularity to 
                                                                         # make sure there are enough fraud cases

```


# Feature importance trend

## Setting up rolling splits
```{r eval=FALSE}
create_rolling_splits <- function(data, window_size = 3, test_size = 1, step = 9) {
  splits <- list()
  unique_years <- sort(unique(data$year))
  
  for (start_year in unique_years) {
    train_end_year <- start_year + window_size - 1
    test_year <- train_end_year + 1
    
    if (test_year > max(unique_years)) break
    
    train_data <- data %>%
      filter(year >= start_year & year <= train_end_year)
    
    test_data <- data %>%
      filter(year == test_year)
    
    split_training <- initial_split(train_data, prop = .8, strata = irregularity)
    
    splits[[paste0(start_year, "-", test_year)]] <- split_training
    
    # Increment start year by step
    start_year <- start_year + step - 1
  }
  
  return(splits)
}

```


```{r eval=FALSE}
rolling_splits <- create_rolling_splits(df.analysis_filt)
```

```{r eval=FALSE}
train_and_assess_model <- function(splits, cores = parallel::detectCores() - 1, num_features = 10) {
  results <- list()
  feature_importance_plots <- list()
  
  doParallel::registerDoParallel(cores = cores)
  
  for (period in names(splits)) {
    print(paste("Processing period:", period))
    
    split_data <- splits[[period]]
    df.analysis_train <- training(split_data)
    df.analysis_test <- testing(split_data)
    
    # Cross-validation within the training data
    cv_folds <- df.analysis_train %>%
      vfold_cv(v = 5, strata = irregularity)
    
    # Recipe definition
    rf_recipe <- recipe(irregularity ~ ., data = df.analysis_train) %>%
      update_role(gvkey, year, sic, irregularity_bin, AUDIT_FEES, AUDITOR_FKEY, new_role = "metadata") %>%
      themis::step_downsample(irregularity)
    
    # Tuning model definition
    rf_model_tune <- rand_forest(mtry = tune(), trees = 500) %>%
      set_mode("classification") %>%
      set_engine("ranger", importance = "permutation", class.weights = c("1" = 122, "0" = 1))
    
    # Workflow
    rf_tune_wf <- workflow() %>%
      add_recipe(rf_recipe) %>%
      add_model(rf_model_tune)
    
    # Metrics
    class_metrics <- metric_set(accuracy, kap, sensitivity, specificity, roc_auc)
    
    # Tuning
    rf_tune_grid <- grid_regular(mtry(range = c(1, 15)), levels = 15)
    
    rf_tune_res <- tune_grid(
      rf_tune_wf,
      resamples = cv_folds,
      grid = rf_tune_grid,
      metrics = class_metrics
    )
    
    # Selecting best model and finalizing workflow
    best_rf <- select_best(rf_tune_res, "sensitivity")
    
    rf_final_wf <- finalize_workflow(rf_tune_wf, best_rf)
    
    # Fit the final model on the training data and assess it
    rf_final_fit <- rf_final_wf %>%
      last_fit(split_data, metrics = class_metrics)
    
    # Collecting test metrics
    test_predictions <- rf_final_fit %>%
      collect_metrics()
    
    # Collect feature importance scores
    vip_rf_scs <- rf_final_fit |>
      extract_fit_parsnip() |>
      vip::vip(geom = "point", num_features = num_features) +
      labs(title = paste("Feature Importance for Period:", period)) +
      theme_classic() +
      theme(
        text = element_text(family = "Times New Roman", size = 16)
      )

    # Extracting model fit
    model_fit <- rf_final_fit %>%
      extract_fit_parsnip()    

   # Extract feature importance values
    importance_values <- model_fit %>%
      extract_fit_engine() %>%
      .$variable.importance

    # Convert to a tidy data frame
    importance_df <- as_tibble(importance_values, rownames = "Variable") %>%
      rename(Importance = value)
    
    # Save the plot
    ggsave(paste0("plots/vip/feature_importance_", period, ".png"), plot = vip_rf_scs, width = 8, height = 4)
    
    results[[period]] <- list(
      test_metrics = test_predictions,
      importance_plot = vip_rf_scs,
      importance_values = importance_df,
      fit = model_fit,
      split = split_data
    )
    
    # Store feature importance plot for comparison
    feature_importance_plots[[period]] <- vip_rf_scs
  }
  
  return(list(results = results, feature_importance_plots = feature_importance_plots))
}


```


```{r eval=FALSE}
rolling_results <- train_and_assess_model(rolling_splits, num_features = 10)
beepr::beep(sound = 1)
rolling_results$results[["2001-2004"]]$importance_values
```

```{r}
 # Define the prediction wrapper function
    pred_wrapper <- function(model, newdata) {
      predict(model, newdata, type = "prob")$.pred_1
    }
    
    importance_df <- vip::vi(model_fit, 
                             method = "permute", 
                             num_features = num_features_df,
                             train = df.analysis_train,
                             target = "irregularity",
                             metric = "roc_auc",
                             pred_wrapper = pred_wrapper) %>%
      as_tibble()
```

# Performance metrics
```{r}
rolling_results$results$`2001-2004`$test_metrics

plot_performance <- function(results) {
  
  metrics_df <- data.frame()
  
  for (period in names(results)) {
    metrics <- results[[period]]$test_metrics
    
    metrics <- metrics %>% filter(.metric == "roc_auc") %>%
      select(.estimate) %>%
      mutate(Period = period, .before = .estimate)
    
    metrics_df <- rbind(metrics_df, metrics)
  }
  return(metrics_df)
}

test <- plot_performance(rolling_results$results)

metrics_plot <- ggplot() +
    geom_path(data = test, aes(x = Period, y = .estimate, group = 1)) +
    geom_point(data = test, aes(x = Period, y = .estimate)) +
    labs(title = "",
         x = "Period",
         y = "ROC-AUC") +
    theme_classic() +
    theme(
      text = element_text(family = "Times New Roman", size = 16),
      axis.text.x = element_text(angle = 45, hjust = 1)
    )

ggsave(file = "plots/metrics_plot.png", metrics_plot, width = 12, height = 6)

```



# Feature importance over time
```{r}
# Function to plot variable importance over periods
plot_variable_importance_over_time <- function(results, variables, file_suffix = "default") {
  # Create an empty data frame to store the variable importance values
  importance_over_time <- data.frame()
  
  # Create an empty data frame to store the maximum importance values for each period
  max_importance_over_time <- data.frame()
  
  # Iterate over each period in the results
  for (period in names(results)) {
    importance_df <- results[[period]]$importance_values
    
    # Check if importance_df is not NULL
    if (!is.null(importance_df)) {
      # Add the period to the data frame
      importance_df <- importance_df %>%
        mutate(Period = period)
      
      # Bind the data to the main data frame
      importance_over_time <- bind_rows(importance_over_time, importance_df)
      
      # Find the maximum importance value for this period
      max_importance <- importance_df %>%
        summarize(MaxImportance = max(Importance)) %>%
        mutate(Period = period)
      
      # Bind the maximum importance to the max_importance_over_time data frame
      max_importance_over_time <- bind_rows(max_importance_over_time, max_importance)
    }
  }
  
  # Filter for the specified variables
  importance_over_time <- importance_over_time %>%
    filter(Variable %in% variables)
  
  # Convert the Period column to a factor to maintain the order
  importance_over_time$Period <- factor(importance_over_time$Period, levels = names(results))
  max_importance_over_time$Period <- factor(max_importance_over_time$Period, levels = names(results))
  
  # Plot the variable importance over time
  importance_plot <- ggplot() +
    geom_line(data = importance_over_time, aes(x = Period, y = Importance, color = Variable, group = Variable)) +
    geom_point(data = importance_over_time, aes(x = Period, y = Importance, color = Variable, group = Variable)) +
    geom_line(data = max_importance_over_time, aes(x = Period, y = MaxImportance, group = 1), color = "black", linetype = "dashed", size = 0.5) +
    geom_point(data = max_importance_over_time, aes(x = Period, y = MaxImportance), color = "black", size = 1) +
    labs(title = "",
         x = "Period",
         y = "Importance",
         color = "Feature") +
    theme_classic() +
    theme(
      text = element_text(family = "Times New Roman", size = 16),
      axis.text.x = element_text(angle = 45, hjust = 1)
    )
  
  # Print the plot
  print(importance_plot)
  
  # Save the plot with the specified suffix
  file_name <- paste0("plots/variable_importance_over_time_", file_suffix, ".png")
  ggsave(file_name, plot = importance_plot, width = 12, height = 6)
}
```


## Showing results
### Most important features

```{r}
variables_to_display <- c("AUDITOR_RESIGN", "manuf_company", "RES_ADVERSE")
plot_variable_importance_over_time(rolling_results$results, variables_to_display, file_suffix = "most_imp")
```


### Pressure
```{r}
variables_to_display <- c("gmi", "aqi", "lvgi", "debt_assets")
plot_variable_importance_over_time(rolling_results$results, variables_to_display, file_suffix = "FT_pressure")
```
### Opportunity
```{r}
variables_to_display <- c("CEO_CHAIR", "inv_sales", "rec_sales")
plot_variable_importance_over_time(rolling_results$results, variables_to_display, file_suffix = "FT_opportunity")
```
### Rationalization
```{r}
variables_to_display <- c("AUDITOR_RESIGN", "AUDITOR_BIG4", "rec_sales")
plot_variable_importance_over_time(rolling_results$results, variables_to_display, file_suffix = "FT_rationalization")
```



# PDP
```{r eval=FALSE}
final_model <- extract_fit_parsnip(rf_final_fit)

# Create an explainer object using DALEX
explainer_rf <- explain(
  model = final_model,
  data = dplyr::select(df.analysis_test, -irregularity),
  y = df.analysis_test$irregularity,
  label = "Random Forest"
)

# Generate Partial Dependence Plots for selected features
pdp_rf <- model_profile(
  explainer = explainer_rf,
  variables = c("manuf_company")#, "AUDITOR_RESIGN", "rd_sale", "RES_IMPROVES", "AUDITOR_BIG4") # Replace with your feature names
)

```


```{r eval=FALSE}
generate_partial_dependence_plots <- function(rolling_results, df_analysis_filt, variables) {
  pdp_plots <- list()
  
  for (period in names(rolling_results$results)) {
    model_fit <- rolling_results$results[[period]]$fit
    df_split <- rolling_results$results[[period]]$split
    df_test <- testing(df_split)
    
    # Prepare explainer
    explainer_rf <- explain(
      model = model_fit,
      data = dplyr::select(df_test, -irregularity),
      y = df_test$irregularity,
      label = paste("Random Forest ", period)
    )
    
    # Generate Partial Dependence Plots for selected features
    pdp_rf <- DALEX::model_profile(
      explainer = explainer_rf,
      variables = variables
    )
    
    pdp_plots[[period]] <- pdp_rf
  }
  
  return(pdp_plots)
}
```

# Partial dependence plots
```{r eval=FALSE}
features <- c("manuf_company", "AUDITOR_RESIGN")

pdp_plots <- generate_partial_dependence_plots(rolling_results = rolling_results, 
                                               df_analysis_filt = df.analysis_filt, 
                                               variables = features)



```

```{r eval=FALSE}
plot_partial_dependence_ggplot <- function(pdp_data) {
  pdp_plots <- list()
  
  for (period in seq_along(pdp_data)) {
    pdp_df <- pdp_data[[period]]$agr_profiles
    
    for (variable in unique(pdp_df$`_vname_`)) {
      plot_data <- pdp_df %>% filter(`_vname_` == variable)
      
      p <- ggplot(plot_data, aes(x = `_x_`, y = `_yhat_`)) +
        geom_line() +
        geom_point() +
        labs(
          title = paste("Partial Dependence Plot:", variable, "Period", period),
          x = variable,
          y = "Predicted Value"
        ) +
        theme_classic()
      
      pdp_plots[[paste(variable, period, sep = "_")]] <- p
    }
  }
  
  return(pdp_plots)
}
```

```{r eval=FALSE}
# Function to display the plots
display_pdp_plots <- function(pdp_plots) {
  for (plot_name in names(pdp_plots)) {
    print(pdp_plots[[plot_name]])
  }
}
```

```{r eval=FALSE}
# Plot the partial dependence data using ggplot2
pdp_plots <- plot_partial_dependence_ggplot(pdp_plots)

# Display the plots
display_pdp_plots(pdp_plots)

pdp_plots$AUDITOR_RESIGN_2
```